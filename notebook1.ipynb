{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./train.csv',parse_dates=[0],infer_datetime_format=True)\n",
    "df_test = pd.read_csv('./test.csv',parse_dates=[0],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of training set: \"+ str(df_train.shape))\n",
    "print(\"Size of test set: \"+ str(df_test.shape))\n",
    "print('\\n')\n",
    "print('columns in train: '+str(df_train.columns.tolist()))\n",
    "print('columns in test: '+str(df_test.columns.tolist()))\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_train.set_index(['Junction','DateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_values = df_tmp.index.get_level_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_targets = df_tmp.groupby([level_values(0)] + [pd.Grouper(freq='1M', level=-1)])['Vehicles'].sum()\n",
    "time_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_tmp\n",
    "del time_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lag_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train.pivot(index='DateTime', columns='Junction', values='Vehicles')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value=round(train[4].max())/1.0\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_lag_features(df, n_in=1,n_out=1,dropnan=True):\n",
    "    n_vars = df.shape[1]\n",
    "    cols, names = list(), list()\n",
    "    #input sequence (t-n,.....t-1)\n",
    "    for i in range(n_in,0,-1):\n",
    "        cols.append(df.shift(i))\n",
    "        names+=[('Junction %d (H-%d)' %(j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t,t+1,.....t+n)\n",
    "    for i in range(0,n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names+=[('Junction %d (H)' %(j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names+=[('Junction %d (H+%d)' %(j+1,i)) for j in range(n_vars)]\n",
    "    #put it all together\n",
    "    agg = pd.concat(cols,axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train= gen_lag_features(train)\n",
    "Xy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "Xy_train[Xy_train.columns]= scaler.fit_transform(Xy_train[Xy_train.columns])\n",
    "\n",
    "Xy_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and valid (and normalize for real)Â¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Xy_train[Xy_train.index < '2017-04-01'].iloc[:,0:4]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= Xy_train[Xy_train.index < '2017-04-01'].iloc[:,4:]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train.values,axis=2)\n",
    "print(X_train.shape)\n",
    "\n",
    "y_train= y_train.values\n",
    "print(y_train.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.initializers import he_normal\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "regressor= Sequential()\n",
    "\n",
    "#Adding the input layer and the LSTM layer\n",
    "regressor.add(LSTM(units = 50,activation='relu',\n",
    "                   kernel_initializer= he_normal(seed=0),input_shape=(None,1)))\n",
    "\n",
    "#output for 4 junctions\n",
    "regressor.add(Dense(units=4))\n",
    "\n",
    "#Compiling the RNN\n",
    "regressor.compile(optimizer='adam',loss= root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train,y_train,batch_size=120,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = Xy_train[Xy_train.index >='2017-04-01'].iloc[:,0:4]\n",
    "X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid=np.expand_dims(X_valid.values,axis=2)\n",
    "y_pred= regressor.predict(X_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we rescale y in the integer count range\n",
    "# to do that we must first reconcatenate with the X data as scaler expects a shape of 8\n",
    "\n",
    "y_pred = scaler.inverse_transform(np.concatenate((X_valid.squeeze(), y_pred),axis=1))[:,4:]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_truth= train[train.index >= '2017-04-01']\n",
    "y_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising Result for the junctions\n",
    "for junction in range(4):\n",
    "    plt.figure\n",
    "    plt.plot(y_truth.values[:,junction],color='green', label='Real traffic')\n",
    "    plt.plot(y_pred[:,junction],color='red',label ='Predicted traffic')\n",
    "    plt.title('Traffic Forecasting at junction %i' % (junction+1))\n",
    "    plt.xlabel('Number of hours from Start')\n",
    "    plt.ylabel('Traffic')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def rmse(y_true,y_pred):\n",
    "    return sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(y_truth,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "trdf = pd.read_csv('./train.csv')\n",
    "trainMat = trdf.values\n",
    "\n",
    "tedf = pd.read_csv('./test.csv')\n",
    "testMat = tedf.values\n",
    "\n",
    "train = []\n",
    "target = []\n",
    "print(trainMat)\n",
    "\n",
    "for i in trainMat:\n",
    "    s = i[3]\n",
    "    year = s / (10**7)\n",
    "    s = s % (10**7)\n",
    "    month = s / (10**5)\n",
    "    s = s % (10**5)\n",
    "    date = s / (10**3)\n",
    "    s = s % (10**3)\n",
    "    time = s / (10)\n",
    "    s = s % (10)\n",
    "    junction = s\n",
    "    train.append([year, month, date, time, junction])\n",
    "    target.append(i[2])\n",
    "\n",
    "X = np.array(train)\n",
    "y = np.array(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jun1=[]\n",
    "jun2=[]\n",
    "jun3=[]\n",
    "jun4=[]\n",
    "jun5=[]\n",
    "jun=[jun1,jun2,jun3,jun4,jun5]\n",
    "for i in range(0,len(train),24):\n",
    "    ct=0\n",
    "    for j in range(24):\n",
    "        ct+=target[i+j]\n",
    "    jun[train[i][4]-1].append(ct)\n",
    "jun[3]=[0]*(len(jun[0])-len(jun[3]))+jun[3]\n",
    "print(len(jun[0]),len(jun[1]),len(jun[2]),len(jun[3]))\n",
    "\n",
    "k=7\n",
    "week=[[] for i in range(k)]\n",
    "for i in range(len(jun[1])):\n",
    "    week[i%k].append(jun[1][i])\n",
    "for i in range(k):\n",
    "    print(np.mean(week[i]))\n",
    "hour=[[] for i in range(24)]\n",
    "for i in range(len(jun[0])*24+len(jun[1])*24, len(jun[0])*24+len(jun[1])*24+len(jun[2])*24):\n",
    "    hour[i%24].append(target[i])\n",
    "for i in range(24):\n",
    "    print(np.mean(hour[i]))\n",
    "\n",
    "temp=[-i for i in jun[3]]\n",
    "jun[4]=np.add(jun[2],temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(len(week)):\n",
    "    plt.plot(week[i],'blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(jun[0],'yellow')\n",
    "plt.show()\n",
    "plt.plot(jun[1],'red')\n",
    "plt.show()\n",
    "plt.plot(jun[2],'green')\n",
    "plt.show()\n",
    "plt.plot(jun[3],'blue')\n",
    "plt.show()\n",
    "plt.plot(jun[4],'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf=StratifiedKFold(n_splits=7)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clfl=RandomForestClassifier(criterion='entropy',min_samples_split=100,min_samples_leaf=10,max_depth=12)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfl.fit(X,y)\n",
    "pred = clfl.predict(X)\n",
    "val1=(accuracy_score(y,pred)*100)\n",
    "print(\"Accuracy Score for Random Forest :\",val1*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "DT = tree.DecisionTreeClassifier()\n",
    "DT.fit(X,y)\n",
    "predictions = DT.predict(X)\n",
    "val2= (accuracy_score(y,pred)*100)\n",
    "print(\"Accuracy score for Decision tree classifer : \",val2*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
